{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cell 1 - Imports + Config",
   "id": "44badd571f9521ae"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-02T00:00:03.191101Z",
     "start_time": "2025-12-02T00:00:03.187540Z"
    }
   },
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# ---- CONFIG ----\n",
    "\n",
    "data_root = \"/Users/dominicschlegel/PycharmProjects/LearningByDoing/data/ImageNetSubset\"  # folder with binder_0000041.JPEG etc.\n",
    "\n",
    "batch_size    = 32\n",
    "num_epochs    = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "print(\"Data root:\", data_root)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Data root: /Users/dominicschlegel/PycharmProjects/LearningByDoing/data/ImageNetSubset\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cell 2 - Transformations, Dataset, DataLoader",
   "id": "4783a749753bec73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:00:03.277005Z",
     "start_time": "2025-12-02T00:00:03.215823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2 (clean version with train/val split)\n",
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# 1) Collect paths\n",
    "all_image_paths = sorted(glob.glob(os.path.join(data_root, \"*.JPEG\")))\n",
    "if len(all_image_paths) == 0:\n",
    "    raise RuntimeError(\"No .JPEG images found in your data folder.\")\n",
    "\n",
    "# 2) Extract class names (classname_index.JPEG)\n",
    "def extract_classname(path):\n",
    "    filename = os.path.basename(path)\n",
    "    name_no_ext = filename.split(\".\")[0]\n",
    "    classname = name_no_ext.split(\"_\")[0]\n",
    "    return classname\n",
    "\n",
    "# 3) Build class maps\n",
    "classnames = sorted({extract_classname(p) for p in all_image_paths})\n",
    "class_to_idx = {c: i for i, c in enumerate(classnames)}\n",
    "\n",
    "num_classes = len(classnames)\n",
    "\n",
    "# 4) Train/val split\n",
    "random.shuffle(all_image_paths)\n",
    "val_split = 0.2\n",
    "num_val = int(len(all_image_paths) * val_split)\n",
    "\n",
    "val_paths = all_image_paths[:num_val]\n",
    "train_paths = all_image_paths[num_val:]\n",
    "\n",
    "print(\"Train:\", len(train_paths))\n",
    "print(\"Val:\", len(val_paths))\n",
    "\n",
    "# 5) Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_transform_augmentation = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),   # flip left-right\n",
    "    transforms.RandomRotation(10),            # rotate +/- 10 degrees\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 6) Dataset class\n",
    "class SimpleImageDataset(Dataset):\n",
    "    def __init__(self, paths, transform):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "\n",
    "        classname = extract_classname(p)\n",
    "        label = class_to_idx[classname]\n",
    "        return img, label\n",
    "\n",
    "# 7) Create datasets + loaders\n",
    "train_dataset = SimpleImageDataset(train_paths, transform=train_transform_augmentation)\n",
    "val_dataset   = SimpleImageDataset(val_paths,   transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n"
   ],
   "id": "538ca699b76de522",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 10800\n",
      "Val: 2700\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define Model",
   "id": "11b30a0d76377ef7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:00:03.351540Z",
     "start_time": "2025-12-02T00:00:03.281217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) Convolutional \"feature extractor\"\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # [B, 3, 128,128] -> [B,32,128,128]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # [B,32,128,128] -> [B,32,64,64]\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # [B,32,64,64]  -> [B,64,64,64]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # [B,64,64,64]  -> [B,64,32,32]\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),# [B,64,32,32]  -> [B,128,32,32]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # [B,128,32,32] -> [B,128,16,16]\n",
    "        )\n",
    "\n",
    "        # 2) Linear \"classifier\" head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                                # [B,128,16,16] -> [B, 128*16*16]\n",
    "            nn.Linear(128 * 16 * 16, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# create model instance and move it to the device (M1 / CPU / CUDA)\n",
    "num_classes = len(class_to_idx)  # use discovered classes\n",
    "model = SimpleCNN(num_classes).to(device)\n",
    "print(model)"
   ],
   "id": "1069429a2c0968b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=32768, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loss function + optimizer\n",
   "id": "6e27b4da94ad301e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:00:03.360044Z",
     "start_time": "2025-12-02T00:00:03.357559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 4: loss function + optimizer\n",
    "\n",
    "# For multi-class classification, this is the standard choice:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adam is a common optimizer that usually works well out-of-the-box\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"Loss function:\", criterion)\n",
    "print(\"Optimizer:\", optimizer)\n"
   ],
   "id": "bb178b361d2e2365",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Debug cell",
   "id": "a46095e017182e78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:00:03.553726Z",
     "start_time": "2025-12-02T00:00:03.367064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Debug cell: take one batch and run it through the model\n",
    "\n",
    "imgs, labels = next(iter(train_loader))\n",
    "print(\"Batch imgs shape:\", imgs.shape)     # expected: [batch_size, 3, 128, 128]\n",
    "print(\"Batch labels shape:\", labels.shape) # expected: [batch_size]\n",
    "\n",
    "imgs = imgs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(imgs)\n",
    "print(\"Outputs shape:\", outputs.shape)     # expected: [batch_size, num_classes]\n",
    "\n",
    "loss = criterion(outputs, labels)\n",
    "print(\"Loss:\", loss.item())\n"
   ],
   "id": "d24732f57200bcd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch imgs shape: torch.Size([32, 3, 128, 128])\n",
      "Batch labels shape: torch.Size([32])\n",
      "Outputs shape: torch.Size([32, 10])\n",
      "Loss: 2.29620361328125\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Validation Loop\n",
   "id": "c57408a13eae65da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:00:03.566094Z",
     "start_time": "2025-12-02T00:00:03.563856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 5: validation loop\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()  # turn off dropout/batchnorm\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # disable gradients\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss = running_loss / total\n",
    "    val_acc = correct / total\n",
    "    return val_loss, val_acc\n"
   ],
   "id": "d1193e1056e37c9e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training Loop",
   "id": "95a9c217b331f572"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:05:22.121041Z",
     "start_time": "2025-12-02T00:00:03.571141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 6: training loop with validation + best-model saving\n",
    "\n",
    "best_val_acc = 0.0\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # training mode\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = running_correct / total\n",
    "\n",
    "    # ---- VALIDATION ----\n",
    "    val_loss, val_acc = validate(model, val_loader)\n",
    "\n",
    "    #writer.add...\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}  |  Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f}  |  Val   Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ---- SAVE BEST MODEL ----\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"  ðŸ”¥ New best model saved! (Val Acc: {best_val_acc:.4f})\")\n"
   ],
   "id": "8bbbec13f70d984b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  Train Loss: 2.1406  |  Train Acc: 0.2101\n",
      "  Val   Loss: 2.0414  |  Val   Acc: 0.2622\n",
      "  ðŸ”¥ New best model saved! (Val Acc: 0.2622)\n",
      "Epoch 2/5\n",
      "  Train Loss: 2.0233  |  Train Acc: 0.2798\n",
      "  Val   Loss: 2.0117  |  Val   Acc: 0.2741\n",
      "  ðŸ”¥ New best model saved! (Val Acc: 0.2741)\n",
      "Epoch 3/5\n",
      "  Train Loss: 1.8962  |  Train Acc: 0.3319\n",
      "  Val   Loss: 1.8938  |  Val   Acc: 0.3381\n",
      "  ðŸ”¥ New best model saved! (Val Acc: 0.3381)\n",
      "Epoch 4/5\n",
      "  Train Loss: 1.7982  |  Train Acc: 0.3750\n",
      "  Val   Loss: 1.7952  |  Val   Acc: 0.3678\n",
      "  ðŸ”¥ New best model saved! (Val Acc: 0.3678)\n",
      "Epoch 5/5\n",
      "  Train Loss: 1.6988  |  Train Acc: 0.4176\n",
      "  Val   Loss: 1.8251  |  Val   Acc: 0.3796\n",
      "  ðŸ”¥ New best model saved! (Val Acc: 0.3796)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#",
   "id": "af76ff702b998985"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
