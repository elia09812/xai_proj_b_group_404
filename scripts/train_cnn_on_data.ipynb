{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.transforms import transforms, Resize\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T13:56:45.330444Z","iopub.execute_input":"2025-11-12T13:56:45.330711Z","iopub.status.idle":"2025-11-12T13:56:55.107947Z","shell.execute_reply.started":"2025-11-12T13:56:45.330682Z","shell.execute_reply":"2025-11-12T13:56:55.107031Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class ImageNetSubset(Dataset):\n    def __init__(self):\n        self.class_mapping = {\n            'coffee-mug': 0,\n            'notebook': 1,\n            'remote-control': 2,\n            'soup-bowl': 3,\n            'teapot': 4,\n            'wooden-spoon': 5,\n            'computer-keyboard': 6,\n            'mouse': 7,\n            'binder': 8,\n            'toilet-tissue': 9\n        }\n\n        DATA_PATH = os.path.join('..', 'data', 'ImageNetSubset')\n        file_names = os.listdir(DATA_PATH)\n\n        self.n_samples = len(file_names)\n\n        transform_compose = transforms.Compose([transforms.PILToTensor()])\n        transform_resize = transforms.Resize(size=(256, 192))\n\n        img_tensor = torch.empty(self.n_samples, 3, 256, 192, dtype=torch.int32)\n        label_tensor = torch.empty(self.n_samples, dtype=torch.int32)\n\n        print('Data loading progress:', end='')\n        for i in tqdm(range(self.n_samples)):\n            IMG_PATH = os.path.join('..', 'data', 'ImageNetSubset', file_names[i])\n\n            label_str = file_names[i].split('_')[0]\n            label_int = self.class_mapping[label_str]\n\n            image = Image.open(IMG_PATH)\n            image_t = transform_compose(image)\n            image_t = transform_resize(image_t)\n\n            img_tensor[i] = image_t\n            label_tensor[i] = label_int\n\n        self.x = img_tensor\n        self.y = label_tensor\n\n\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n\n    def __len__(self) -> int:\n        return self.n_samples","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"subset = ImageNetSubset()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x, y = subset[1001]\n\nprint(list(subset.class_mapping)[y])\nplt.imshow(x.permute(1, 2, 0))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}